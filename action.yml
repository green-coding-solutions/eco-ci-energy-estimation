name: 'Eco CI Energy Estimation'
description: 'Estimate the energy of Linux Github Actions Runner VMs via ML Model'
inputs:
  task:
    description: 'Task to be executed (start-measurement, get-measurement, display-results)'
    required: true
  branch:
    description: 'Used to correctly identify this CI run for the Badge. Uses github.ref_name by default'
    default: ${{ github.ref_name }}
    required: false
  label:
    description: 'Label for the get-measurement task, to mark what this measurement correlates to in your workflow'
    default: null
    required: false
  send-data:
    description: 'Send metrics data to metrics.green-coding.berlin to create and display badge, and see an overview of the energy of your CI runs. Set to false to send no data.'
    default: true
    required: false
  display-table: 
    description: 'Show the energy reading results in a table during display-results step'
    default: true
    required: false
  display-graph: 
    description: 'Show the graph of the energy use over time during display-results step'
    default: true
    required: false
  display-badge: 
    description: 'Shows the badge for the ci run during display-results step'
    default: true
    required: false
outputs:
  data-total-json:
    description: "Contains the data of the total measurement which is retrieved by the 'display-results' task."
    value: ${{ steps.run-total-model.outputs.data-total-json }}
  data-lap-json:
    description: "Contains the data of the most recent measurement which is retrieved by the 'get-measurement' task."
    value: ${{ steps.run-lap-model.outputs.data-lap-json }}
runs:
  using: 'composite'
  steps:
    - id: guard
      if: inputs.task != 'start-measurement' && inputs.task != 'get-measurement' && inputs.task != 'display-results'
      shell: bash
      run: |
          echo 'Please call the Eco-CI Energy Estimation with a valid task name: start-measurement, get-measurement, or display-results' >> $GITHUB_STEP_SUMMARY
          echo "Eco-CI task was called with ${{inputs.task}} instead" >> $GITHUB_STEP_SUMMARY
          fail('Invalid task name specified')

    - id: initialize
      if: inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE'
      name: Setup
      shell: bash
      run: |
        # call the initialize function of setup.sh
        ${{github.action_path}}/scripts/setup.sh initialize -g ${{inputs.display-graph}}

      # To identify the hash for our cache we cannot use the classic mechansim of
      # hashFiles('/tmp/eco-ci/spec-power-model/requirements.txt')
      # hashFiles is restricted to ONLY work in the GITHUB_WORKSPACE which is for the calling action
      # therefore we need to construct the hash ourselfs beforehand and save it to an output variable
    - if:  inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE'
      name: Hash requirements file
      id: hash-requirements
      shell: bash
      run: echo "myhash=$(md5sum /tmp/eco-ci/spec-power-model/requirements.txt | cut -d ' ' -f1)" >> $GITHUB_OUTPUT;

    - if:  inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE'
      name: Cache pip packages
      id: cache-pip
      uses: actions/cache@v3
      env:
        cache-name: cache-pip-packages
      with:
        # npm cache files are stored in `~/.npm` on Linux/macOS
        path: /tmp/eco-ci/venv/lib/python3.10/site-packages
        key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ steps.hash-requirements.outputs.myhash }}
        restore-keys: |
          ${{ runner.os }}-build-${{ env.cache-name }}-${{ steps.hash-requirements.outputs.myhash }}

    - if: inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE' && steps.cache-pip.outputs.cache-hit == 'true'
      name: Inform about cache hit
      continue-on-error: true
      shell: bash
      run: |
        echo "Cache hit succeeded! ðŸ˜€"

    - if: inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE' && steps.cache-pip.outputs.cache-hit != 'true'
      name: Inform about cache hit
      continue-on-error: true
      shell: bash
      run: |
        echo "Cache hit failed! âŒ"


    - if:  inputs.task == 'start-measurement'
      name: Starting measurement
      shell: bash
      # if measurement is started first time the reporter might not have run already
      # we prefer this over manual startint / stopping as it is less error prone for users
      run: |
        ${{github.action_path}}/scripts/setup.sh setup_python
        curl_response=$(curl -s -H "Authorization: Bearer ${{github.token}}" ${{ github.api_url }}/repos/${{ github.repository }}/actions/workflows)
        workflow_id=$(echo $curl_response | jq '.workflows[] | select(.name == "${{ github.workflow }}") | .id')
        ${{github.action_path}}/scripts/vars.sh add_var "WORKFLOW_ID" $workflow_id
        ${{github.action_path}}/scripts/setup.sh start_measurement
        echo "ECO_CI_INIT=DONE" >> $GITHUB_ENV;


    - if:  inputs.task == 'get-measurement'
      id: run-lap-model
      name: Running estimation model
      shell: bash
      run: |
        ${{github.action_path}}/scripts/make_measurement.sh -l "${{inputs.label}}" -r "${{ github.run_id }}" -b "${{inputs.branch}}" -R "${{ github.repository }}" -c ${{ github.sha }} -sd ${{inputs.send-data}} -s "github"
        lap_data_file="/tmp/eco-ci/lap-data.json"
        echo "data-lap-json=$(cat $lap_data_file)" >> $GITHUB_OUTPUT

    - if: inputs.task == 'display-results'
      name: get estimation for total energy
      id: run-total-model
      shell: bash
      run: |
        ${{github.action_path}}/scripts/display_results.sh -dt ${{inputs.display-table}} -dg ${{inputs.display-graph}} -db ${{inputs.display-badge}} -b "${{inputs.branch}}" -r ${{ github.run_id }} -R "${{ github.repository }}" -sd ${{inputs.send-data}} -s "github"
        cat "/tmp/eco-ci/output.txt" >> $GITHUB_STEP_SUMMARY
        total_data_file="/tmp/eco-ci/total-data.json"
        echo "data-total-json=$(cat $total_data_file)" >> $GITHUB_OUTPUT