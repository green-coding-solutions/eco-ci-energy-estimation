name: 'Eco CI Energy Estimation'
description: 'Estimate the energy of Linux Github Actions Runner VMs via ML Model'
inputs:
  task:
    description: 'Task to be executed (start-measurement, get-measurement, display-results)'
    required: true
  branch:
    description: 'Used to correctly identify this CI run for the Badge. Uses github.ref_name by default'
    default: ${{ github.ref_name }}
    required: false
  label:
    description: 'Label for the get-measurement task, to mark what this measurement correlates to in your workflow'
    default: null
    required: false
  send-data:
    description: 'Send metrics data to metrics.green-coding.berlin to create and display badge, and see an overview of the energy of your CI runs. Set to false to send no data.'
    default: true
    required: false
  display-table: 
    description: 'Show the energy reading results in a table during display-results step'
    default: true
    required: false
  display-graph: 
    description: 'Show the graph of the energy use over time during display-results step'
    default: true
    required: false
  display-badge: 
    description: 'Shows the badge for the ci run during display-results step'
    default: true
    required: false
  pr-comment:
    description: 'Add a comment to the PR with the results during display-results step'
    default: false
outputs:
  data-total-json:
    description: "Contains the data of the total measurement which is retrieved by the 'display-results' task."
    value: ${{ steps.run-total-model.outputs.data-total-json }}
  data-lap-json:
    description: "Contains the data of the most recent measurement which is retrieved by the 'get-measurement' task."
    value: ${{ steps.run-lap-model.outputs.data-lap-json }}
runs:
  using: 'composite'
  steps:
    - id: guard
      if: inputs.task != 'start-measurement' && inputs.task != 'get-measurement' && inputs.task != 'display-results' && inputs.task != 'test'
      shell: bash
      run: |
          echo 'Please call the Eco-CI Energy Estimation with a valid task name: start-measurement, get-measurement, or display-results' >> $GITHUB_STEP_SUMMARY
          echo "Eco-CI task was called with ${{inputs.task}} instead" >> $GITHUB_STEP_SUMMARY
          fail('Invalid task name specified')

    - id: initialize
      if: inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE'
      name: Setup
      shell: bash
      run: |
        if command -v python3 &>/dev/null; then
            echo "Python is already installed."
        else
            echo "Python is not installed. Installing..."
            apt-get update
            apt-get install -y python3.10 python3.10-venv
            echo "Python has been installed."
        fi

        python_version=$(python3 --version 2>&1)
        python_major_version=$(python3 -c 'import sys; print(sys.version_info[0])')
        python_minor_version=$(python3 -c 'import sys; print(sys.version_info[1])')
        python_cache_path="${base_root}venv/lib/python${python_major_version}.${python_minor_version}/site-packages"
        echo "python_cache_path=$python_cache_path" >> $GITHUB_OUTPUT


        # call the initialize function of setup.sh
        ${{github.action_path}}/scripts/setup.sh initialize -g ${{inputs.display-graph}}

      # To identify the hash for our cache we cannot use the classic mechansim of
      # hashFiles('/tmp/eco-ci/spec-power-model/requirements.txt')
      # hashFiles is restricted to ONLY work in the GITHUB_WORKSPACE which is for the calling action
      # therefore we need to construct the hash ourselfs beforehand and save it to an output variable
    - if:  inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE'
      name: Hash requirements file
      id: hash-requirements
      shell: bash
      run: echo "myhash=$(md5sum /tmp/eco-ci/spec-power-model/requirements.txt | cut -d ' ' -f1)" >> $GITHUB_OUTPUT;

    - if:  inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE'
      name: Cache pip packages
      id: cache-pip
      uses: actions/cache@v3
      env:
        cache-name: cache-pip-packages
      with:
        # npm cache files are stored in `~/.npm` on Linux/macOS
        path: ${{ steps.initialize.outputs.python_cache_path }}
        key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ steps.hash-requirements.outputs.myhash }}
        restore-keys: |
          ${{ runner.os }}-build-${{ env.cache-name }}-${{ steps.hash-requirements.outputs.myhash }}

    - if: inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE' && steps.cache-pip.outputs.cache-hit == 'true'
      name: Inform about cache hit
      continue-on-error: true
      shell: bash
      run: |
        echo "Cache hit succeeded! 😀"

    - if: inputs.task == 'start-measurement' && env.ECO_CI_INIT != 'DONE' && steps.cache-pip.outputs.cache-hit != 'true'
      name: Inform about cache hit
      continue-on-error: true
      shell: bash
      run: |
        echo "Cache hit failed! ❌"


    - if:  inputs.task == 'start-measurement'
      name: Starting measurement
      shell: bash
      # if measurement is started first time the reporter might not have run already
      # we prefer this over manual startint / stopping as it is less error prone for users
      run: |
        ${{github.action_path}}/scripts/setup.sh setup_python

        if ${{inputs.send-data}}; then
          curl_response=$(curl -s -H "Authorization: Bearer ${{github.token}}" ${{ github.api_url }}/repos/${{ github.repository }}/actions/workflows)
          workflow_id=$(echo $curl_response | jq '.workflows[] | select(.name == "${{ github.workflow }}") | .id')
          ${{github.action_path}}/scripts/vars.sh add_var "WORKFLOW_ID" $workflow_id
        else
          ${{github.action_path}}/scripts/vars.sh add_var "WORKFLOW_ID" ${{github.workflow}}
        fi
        
        ${{github.action_path}}/scripts/setup.sh start_measurement
        echo "ECO_CI_INIT=DONE" >> $GITHUB_ENV;


    - if:  inputs.task == 'get-measurement'
      id: run-lap-model
      name: Running estimation model
      env:
        NAME: ${{ github.workflow }}
      shell: bash
      run: |
        ${{github.action_path}}/scripts/make_measurement.sh -l "${{inputs.label}}" -r "${{ github.run_id }}" -b "${{inputs.branch}}" -R "${{ github.repository }}" -c ${{ github.sha }} -sd ${{inputs.send-data}} -s "github" -n $NAME
        lap_data_file="/tmp/eco-ci/lap-data.json"
        echo "data-lap-json=$(cat $lap_data_file)" >> $GITHUB_OUTPUT

    - if: inputs.task == 'display-results'
      name: get estimation for total energy
      id: run-total-model
      shell: bash
      run: |
        ${{github.action_path}}/scripts/display_results.sh -dt ${{inputs.display-table}} -dg ${{inputs.display-graph}} -db ${{inputs.display-badge}} -b "${{inputs.branch}}" -r ${{ github.run_id }} -R "${{ github.repository }}" -sd ${{inputs.send-data}} -s "github"
        cat "/tmp/eco-ci/output.txt" >> $GITHUB_STEP_SUMMARY
        total_data_file="/tmp/eco-ci/total-data.json"
        echo "data-total-json=$(cat $total_data_file)" >> $GITHUB_OUTPUT

    - if: github.event_name == 'pull_request' && inputs.task == 'test' && inputs.pr-comment == 'true'
      name: Minimize Old Comment and Post New Comment
      id: minimize-comment
      shell: bash
      run: |
        PR_NUMBER="${{ github.event.pull_request.number }}"

       
        FULL_REPO="${{ github.repository }}"
        REPO_NAME="${FULL_REPO#*/}"

        query='query { search(query: \"repo: '${{ github.repository }}' is:pr is:open Eco-CI in:body author:github-actions number:'$PR_NUMBER'\", last:10, type:ISSUE){ edges{ node{ ... on PullRequest{ body title } } } } }'
        echo "DMM---"
        echo "$query"
        RESPONSE=$(curl -H "Authorization: bearer ${{ github.token }}" -X POST -d "{\"query\":\"$query\"}" https://api.github.com/graphql)
        echo "$RESPONSE"
        # Extract and print the comments
        COMMENTS=$(echo $RESPONSE | jq .)
        echo "$COMMENTS"
        echo "---DMM"